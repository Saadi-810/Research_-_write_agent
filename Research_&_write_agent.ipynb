{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tSnX9L_dCX5v",
        "outputId": "941bb6b1-7065-49cf-8b98-f6b24dcd1f73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai_tools\n",
            "  Downloading crewai_tools-0.46.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting chromadb>=0.4.22 (from crewai_tools)\n",
            "  Downloading chromadb-1.0.12-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from crewai_tools) (8.2.1)\n",
            "Collecting crewai>=0.121.1 (from crewai_tools)\n",
            "  Downloading crewai-0.121.1-py3-none-any.whl.metadata (35 kB)\n",
            "Collecting docker>=7.1.0 (from crewai_tools)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting embedchain>=0.1.114 (from crewai_tools)\n",
            "  Downloading embedchain-0.1.128-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting lancedb>=0.5.4 (from crewai_tools)\n",
            "  Downloading lancedb-0.22.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: openai>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from crewai_tools) (1.81.0)\n",
            "Requirement already satisfied: pydantic>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from crewai_tools) (2.11.4)\n",
            "Collecting pyright>=1.1.350 (from crewai_tools)\n",
            "  Downloading pyright-1.1.401-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pytube>=15.0.0 (from crewai_tools)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from crewai_tools) (2.32.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai_tools) (1.2.2.post1)\n",
            "Collecting fastapi==0.115.9 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai_tools) (2.0.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading posthog-4.2.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai_tools) (4.13.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai_tools) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai_tools) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai_tools) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai_tools) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai_tools) (0.15.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai_tools) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai_tools) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai_tools) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai_tools) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai_tools) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai_tools) (4.23.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting appdirs>=1.4.4 (from crewai>=0.121.1->crewai_tools)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting auth0-python>=4.7.1 (from crewai>=0.121.1->crewai_tools)\n",
            "  Downloading auth0_python-4.9.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.121.1->crewai_tools) (1.9.0)\n",
            "Collecting instructor>=1.3.3 (from crewai>=0.121.1->crewai_tools)\n",
            "  Downloading instructor-1.8.3-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting json-repair>=0.25.2 (from crewai>=0.121.1->crewai_tools)\n",
            "  Downloading json_repair-0.46.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting json5>=0.10.0 (from crewai>=0.121.1->crewai_tools)\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting jsonref>=1.1.0 (from crewai>=0.121.1->crewai_tools)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting litellm==1.68.0 (from crewai>=0.121.1->crewai_tools)\n",
            "  Downloading litellm-1.68.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.121.1->crewai_tools) (3.1.5)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http>=1.30.0 (from crewai>=0.121.1->crewai_tools)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pdfplumber>=0.11.4 (from crewai>=0.121.1->crewai_tools)\n",
            "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=1.0.0 (from crewai>=0.121.1->crewai_tools)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting pyvis>=0.3.2 (from crewai>=0.121.1->crewai_tools)\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.121.1->crewai_tools) (2024.11.6)\n",
            "Collecting tomli-w>=1.1.0 (from crewai>=0.121.1->crewai_tools)\n",
            "  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tomli>=2.0.2 (from crewai>=0.121.1->crewai_tools)\n",
            "  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting uv>=0.4.25 (from crewai>=0.121.1->crewai_tools)\n",
            "  Downloading uv-0.7.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm==1.68.0->crewai>=0.121.1->crewai_tools) (3.11.15)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.68.0->crewai>=0.121.1->crewai_tools) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.68.0->crewai>=0.121.1->crewai_tools) (3.1.6)\n",
            "Collecting openai>=1.12.0 (from crewai_tools)\n",
            "  Downloading openai-1.75.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.68.0->crewai>=0.121.1->crewai_tools) (0.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker>=7.1.0->crewai_tools) (2.4.0)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai_tools) (4.13.4)\n",
            "Collecting chromadb>=0.4.22 (from crewai_tools)\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai_tools) (0.3.25)\n",
            "Collecting langchain-cohere<0.4.0,>=0.3.0 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langchain_cohere-0.3.5-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting langchain-community<0.4.0,>=0.3.1 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting langchain-openai<0.3.0,>=0.2.1 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4.0,>=0.3.18 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai_tools) (0.3.42)\n",
            "Collecting mem0ai<0.2.0,>=0.1.54 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading mem0ai-0.1.102-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pypdf<6.0.0,>=5.0.0 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading pypdf-5.5.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.27 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai_tools) (2.0.41)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting tokenizers (from litellm==1.68.0->crewai>=0.121.1->crewai_tools)\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting deprecation (from lancedb>=0.5.4->crewai_tools)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.5.4->crewai_tools) (24.2)\n",
            "Requirement already satisfied: pyarrow>=16 in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.5.4->crewai_tools) (18.1.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai_tools) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai_tools) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai_tools) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai_tools) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.6.1->crewai_tools) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.6.1->crewai_tools) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.6.1->crewai_tools) (0.4.1)\n",
            "Collecting nodeenv>=1.6.0 (from pyright>=1.1.350->crewai_tools)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai_tools) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai_tools) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai_tools) (2025.4.26)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai_tools) (1.1.3)\n",
            "Requirement already satisfied: cryptography>=43.0.1 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai>=0.121.1->crewai_tools) (43.0.3)\n",
            "Requirement already satisfied: pyjwt>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai>=0.121.1->crewai_tools) (2.10.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain>=0.1.114->crewai_tools) (2.7)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.4.22->crewai_tools) (1.2.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from gptcache<0.2.0,>=0.1.43->embedchain>=0.1.114->crewai_tools) (5.5.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.4.22->crewai_tools) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.4.22->crewai_tools) (0.16.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai>=0.121.1->crewai_tools) (0.16)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.12.0->crewai_tools)\n",
            "  Downloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools) (0.3.60)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools) (0.3.8)\n",
            "Collecting cohere<6.0,>=5.5.6 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading cohere-5.15.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting langchain-experimental<0.4.0,>=0.3.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools) (2.2.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools) (0.9.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4.0,>=0.3.18->embedchain>=0.1.114->crewai_tools) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4.0,>=0.3.18->embedchain>=0.1.114->crewai_tools) (0.23.0)\n",
            "Requirement already satisfied: pytz>=2024.1 in /usr/local/lib/python3.11/dist-packages (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools) (2025.2)\n",
            "Collecting qdrant-client>=1.9.1 (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading qdrant_client-1.14.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->crewai_tools) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->crewai_tools) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->crewai_tools) (1.13.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.5->crewai>=0.121.1->crewai_tools) (2.0.0)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting importlib-metadata>=6.8.0 (from litellm==1.68.0->crewai>=0.121.1->crewai_tools)\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->crewai_tools) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai_tools) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting pdfminer.six==20250327 (from pdfplumber>=0.11.4->crewai>=0.121.1->crewai_tools)\n",
            "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai>=0.121.1->crewai_tools) (11.2.1)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.4->crewai>=0.121.1->crewai_tools)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai>=0.121.1->crewai_tools) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai>=0.121.1->crewai_tools) (4.1.0)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai>=0.121.1->crewai_tools) (3.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.4.22->crewai_tools) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.4.22->crewai_tools) (2.19.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0.0,>=2.0.27->embedchain>=0.1.114->crewai_tools) (3.2.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm==1.68.0->crewai>=0.121.1->crewai_tools) (0.31.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.4.22->crewai_tools) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai_tools) (15.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.68.0->crewai>=0.121.1->crewai_tools) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.68.0->crewai>=0.121.1->crewai_tools) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.68.0->crewai>=0.121.1->crewai_tools) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.68.0->crewai>=0.121.1->crewai_tools) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.68.0->crewai>=0.121.1->crewai_tools) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.68.0->crewai>=0.121.1->crewai_tools) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.68.0->crewai>=0.121.1->crewai_tools) (1.20.0)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.5.6->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading fastavro-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.5.6->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading types_requests-2.32.0.20250515-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=43.0.1->auth0-python>=4.7.1->crewai>=0.121.1->crewai_tools) (1.17.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.68.0->crewai>=0.121.1->crewai_tools) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.68.0->crewai>=0.121.1->crewai_tools) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm==1.68.0->crewai>=0.121.1->crewai_tools) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.121.1->crewai_tools) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.121.1->crewai_tools)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.121.1->crewai_tools) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.121.1->crewai_tools) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.121.1->crewai_tools) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.121.1->crewai_tools) (3.0.51)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.121.1->crewai_tools) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.121.1->crewai_tools) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.121.1->crewai_tools) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.68.0->crewai>=0.121.1->crewai_tools) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=0.4.22->crewai_tools) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=0.4.22->crewai_tools) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=0.4.22->crewai_tools) (0.25.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools) (1.33)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.4.22->crewai_tools) (0.1.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.3->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools) (2025.2)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.4.22->crewai_tools)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.4.22->crewai_tools) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=43.0.1->auth0-python>=4.7.1->crewai>=0.121.1->crewai_tools) (2.22)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools) (4.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.121.1->crewai_tools) (0.8.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools) (3.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.121.1->crewai_tools) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.121.1->crewai_tools) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (0.6.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools) (4.1.0)\n",
            "Downloading crewai_tools-0.46.0-py3-none-any.whl (606 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.2/606.2 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai-0.121.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.2/320.2 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litellm-1.68.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading embedchain-0.1.128-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.3/211.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lancedb-0.22.1-cp39-abi3-manylinux_2_28_x86_64.whl (31.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.8/31.8 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.75.0-py3-none-any.whl (646 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyright-1.1.401-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading auth0_python-4.9.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading instructor-1.8.3-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.6/345.6 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.46.0-py3-none-any.whl (22 kB)\n",
            "Downloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_cohere-0.3.5-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mem0ai-0.1.102-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.0/156.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.33.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.33.1-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.54b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.5.0-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
            "Downloading uv-0.7.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading cohere-5.15.0-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qdrant_client-1.14.2-py3-none-any.whl (327 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading fastavro-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading types_requests-2.32.0.20250515-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=f9c659e044846036e30917aed00a5996042bcfaca8b635e00b8f63f4f312225d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: schema, pypika, monotonic, durationpy, appdirs, uvloop, uvicorn, uv, types-requests, tomli-w, tomli, pytube, python-dotenv, pysbd, pypdfium2, pypdf, portalocker, overrides, opentelemetry-util-http, opentelemetry-proto, nodeenv, mypy-extensions, mmh3, marshmallow, jsonref, json5, json-repair, jiter, jedi, importlib-metadata, humanfriendly, httpx-sse, httptools, fastavro, deprecation, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, typing-inspect, starlette, pyright, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, gptcache, docker, coloredlogs, alembic, tokenizers, pyvis, pydantic-settings, pdfminer.six, opentelemetry-semantic-conventions, openai, onnxruntime, lancedb, kubernetes, fastapi, dataclasses-json, auth0-python, qdrant-client, pdfplumber, opentelemetry-sdk, opentelemetry-instrumentation, litellm, instructor, cohere, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, mem0ai, langchain-openai, opentelemetry-instrumentation-fastapi, langchain-community, chromadb, langchain-experimental, crewai, langchain-cohere, embedchain, crewai_tools\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.10.0\n",
            "    Uninstalling jiter-0.10.0:\n",
            "      Successfully uninstalled jiter-0.10.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.7.0\n",
            "    Uninstalling importlib_metadata-8.7.0:\n",
            "      Successfully uninstalled importlib_metadata-8.7.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.81.0\n",
            "    Uninstalling openai-1.81.0:\n",
            "      Successfully uninstalled openai-1.81.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.52.2 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alembic-1.16.1 appdirs-1.4.4 asgiref-3.8.1 auth0-python-4.9.0 backoff-2.2.1 bcrypt-4.3.0 chroma-hnswlib-0.7.6 chromadb-0.5.23 cohere-5.15.0 coloredlogs-15.0.1 crewai-0.121.1 crewai_tools-0.46.0 dataclasses-json-0.6.7 deprecated-1.2.18 deprecation-2.1.0 docker-7.1.0 durationpy-0.10 embedchain-0.1.128 fastapi-0.115.9 fastavro-1.11.1 gptcache-0.1.44 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 importlib-metadata-8.6.1 instructor-1.8.3 jedi-0.19.2 jiter-0.8.2 json-repair-0.46.0 json5-0.12.0 jsonref-1.1.0 kubernetes-32.0.1 lancedb-0.22.1 langchain-cohere-0.3.5 langchain-community-0.3.24 langchain-experimental-0.3.4 langchain-openai-0.2.14 litellm-1.68.0 marshmallow-3.26.1 mem0ai-0.1.102 mmh3-5.1.0 monotonic-1.6 mypy-extensions-1.1.0 nodeenv-1.9.1 onnxruntime-1.22.0 openai-1.75.0 opentelemetry-api-1.33.1 opentelemetry-exporter-otlp-proto-common-1.33.1 opentelemetry-exporter-otlp-proto-grpc-1.33.1 opentelemetry-exporter-otlp-proto-http-1.33.1 opentelemetry-instrumentation-0.54b1 opentelemetry-instrumentation-asgi-0.54b1 opentelemetry-instrumentation-fastapi-0.54b1 opentelemetry-proto-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 opentelemetry-util-http-0.54b1 overrides-7.7.0 pdfminer.six-20250327 pdfplumber-0.11.6 portalocker-2.10.1 posthog-3.25.0 pydantic-settings-2.9.1 pypdf-5.5.0 pypdfium2-4.30.1 pypika-0.48.9 pyright-1.1.401 pysbd-0.3.4 python-dotenv-1.1.0 pytube-15.0.0 pyvis-0.3.2 qdrant-client-1.14.2 schema-0.7.7 starlette-0.45.3 tokenizers-0.20.3 tomli-2.2.1 tomli-w-1.2.0 types-requests-2.32.0.20250515 typing-inspect-0.9.0 uv-0.7.9 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "8d36035a378041f08b031dba2cf8b9cc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install crewai_tools python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "I2Cv41RpCf-O"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew"
      ],
      "metadata": {
        "id": "2ZyEExaQEA7R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Get API configuration from environment variables\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "OPENAI_API_BASE = os.environ.get(\"OPENAI_API_BASE\", \"https://api.mistral.ai/v1\")\n",
        "OPENAI_MODEL_NAME = os.environ.get(\"OPENAI_MODEL_NAME\", \"mistral-small\")\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    raise ValueError(\"OPENAI_API_KEY not found. Please set it in your .env file or environment variables.\")\n",
        "\n",
        "# Set them in os.environ as crewai might expect them there directly\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "os.environ[\"OPENAI_API_BASE\"] = OPENAI_API_BASE\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = OPENAI_MODEL_NAME"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "qRwdyi0PGFPq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Agent Planner**\n",
        "\n",
        "Plan how blog is actually will be writen"
      ],
      "metadata": {
        "id": "KzlvCmvUbzQ0"
      }
    },
    {
      "source": [
        "planner=Agent(\n",
        "    role=\"Content Plnner\",\n",
        "    goal=\" plan  enagaging and fact based content on {topic}\",\n",
        "    backstory=\"You're working on planning a blog article \"\n",
        "              \"about the topic: {topic}.\"\n",
        "              \"You collect information that helps the \"\n",
        "              \"audience learn something \"\n",
        "              \"and make informed decisions. \"\n",
        "              \"Your work is the basis for \"\n",
        "              \"the Content Writer to write an article on this topic.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        "\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZIh_EdlFF6J",
        "outputId": "de7f3df7-2b43-4925-841a-fffbd2f967c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Agent Writer**\n"
      ],
      "metadata": {
        "id": "8PNnu53icH8v"
      }
    },
    {
      "source": [
        "writer=Agent(\n",
        "    role=\"Content Writer\",\n",
        "    goal=\"write a meaningfull and factbased and\"\n",
        "    \" accurate opinion peice about this {topic}\",\n",
        "    backstory=\"You're working on a writing \"\n",
        "              \"a new opinion piece about the topic: {topic}. \"\n",
        "              \"You base your writing on the work of \"\n",
        "              \"the Content Planner, who provides an outline \"\n",
        "              \"and relevant context about the topic. \"\n",
        "              \"You follow the main objectives and \"\n",
        "              \"direction of the outline, \"\n",
        "              \"as provide by the Content Planner. \"\n",
        "              \"You also provide objective and impartial insights \"\n",
        "              \"and back them up with information \"\n",
        "              \"provide by the Content Planner. \"\n",
        "              \"You acknowledge in your opinion piece \"\n",
        "              \"when your statements are opinions \"\n",
        "              \"as opposed to objective statements.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEFs9QQcYOmO",
        "outputId": "718a2d91-9914-44dd-d251-abe77675bb1c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Agent Editor**\n"
      ],
      "metadata": {
        "id": "mm99I2fVczlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "editor=Agent(\n",
        "    role=\"Content Editor\",\n",
        "    goal=\"Edit the  give blog to allign\"\n",
        "          \"with the Organization style\",\n",
        "    backstory=\"You are an editor who receives a blog post \"\n",
        "              \"from the Content Writer. \"\n",
        "              \"Your goal is to review the blog post \"\n",
        "              \"to ensure that it follows journalistic best practices,\"\n",
        "              \"provides balanced viewpoints \"\n",
        "              \"when providing opinions or assertions, \"\n",
        "              \"and also avoids major controversial topics \"\n",
        "              \"or opinions when possible.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U03MydHAELSO",
        "outputId": "837f3d5e-45be-439e-cc95-1bb5d31d881c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Creating Task**\n",
        "- Define task, and provide them with `description`, `expected output` and `agent`.\n",
        "\n",
        "\n",
        "##**Taks : Plan**"
      ],
      "metadata": {
        "id": "6JzF9IhZdscp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plan=Task(\n",
        "    description=(\n",
        "        \"1. Prioritize the latest trends, key players, \"\n",
        "            \"and noteworthy news on {topic}.\\n\"\n",
        "        \"2. Identify the target audience, considering \"\n",
        "            \"their interests and pain points.\\n\"\n",
        "        \"3. Develop a detailed content outline including \"\n",
        "            \"an introduction, key points, and a call to action.\\n\"\n",
        "        \"4. Include SEO keywords and relevant data or sources.\"\n",
        "    ),\n",
        "    expected_output=\n",
        "        \"A comprehensive content plan document \"\n",
        "        \"with an outline, audience analysis, \"\n",
        "        \"SEO keywords, and resources.\",\n",
        "\n",
        "    agent=planner\n",
        ")\n"
      ],
      "metadata": {
        "id": "Nm_FtYQQdXBa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plan=Task(\n",
        "    description=(\"Proofread the given blog post for \"\n",
        "                 \"grammatical errors and \"\n",
        "                 \"alignment with the brand's voice.\"),\n",
        "        expected_output=\"A well-written blog post in markdown format, \"\n",
        "                        \"ready for publication, \"\n",
        "                        \"each section should have 2 or 3 paragraphs.\",\n",
        "    agent=editor\n",
        ")\n"
      ],
      "metadata": {
        "id": "swFuFJxbhXWO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Task: Write**##\n"
      ],
      "metadata": {
        "id": "k3QMjEMLfX1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "write=Task(\n",
        "    description=(\n",
        "        \"1. Use the content plan to craft a compelling \"\n",
        "            \"blog post on {topic}.\\n\"\n",
        "        \"2. Incorporate SEO keywords naturally.\\n\"\n",
        "\t\t\"3. Sections/Subtitles are properly named \"\n",
        "            \"in an engaging manner.\\n\"\n",
        "        \"4. Ensure the post is structured with an \"\n",
        "            \"engaging introduction, insightful body, \"\n",
        "            \"and a summarizing conclusion.\\n\"\n",
        "        \"5. Proofread for grammatical errors and \"\n",
        "            \"alignment with the brand's voice.\\n\"\n",
        "    ),\n",
        "    expected_output=\"A well-written blog post \"\n",
        "        \"in markdown format, ready for publication, \"\n",
        "        \"each section should have 2 or 3 paragraphs.\",\n",
        "    agent=writer\n",
        ")"
      ],
      "metadata": {
        "id": "4Upjn7FhfP7f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Writer**"
      ],
      "metadata": {
        "id": "JuDxmzYefxnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edit = Task(\n",
        "    description=(\"Proofread the given blog post for \"\n",
        "                 \"grammatical errors and \"\n",
        "                 \"alignment with the brand's voice.\"),\n",
        "        expected_output=\"A well-written blog post in markdown format, \"\n",
        "                        \"ready for publication, \"\n",
        "                        \"each section should have 2 or 3 paragraphs.\",\n",
        "    agent=editor\n",
        ")"
      ],
      "metadata": {
        "id": "ukZslR7pfxIz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Crteating the Crew Of Agent**\n"
      ],
      "metadata": {
        "id": "EFnhbA4vgS75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "    agents=[planner, writer, editor],\n",
        "    tasks=[plan, write, edit],\n",
        "    verbose=0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6V_bKzjgRAX",
        "outputId": "666acc45-bdde-40c0-c77e-0c2625a512fe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Running the Crew**"
      ],
      "metadata": {
        "id": "xnpcxKTbNZtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = crew.kickoff(inputs={\"topic\":\"Pakistan Vs India \"})"
      ],
      "metadata": {
        "id": "R2L_4Kr4goFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "634f4041-ebdc-4ecf-f488-1cbcf2ff1d16"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Editor\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mProofread the given blog post for grammatical errors and alignment with the brand's voice.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Editor\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Introduction:\n",
            "\n",
            "It is essential to have a well-written and informative introduction that grabs the reader's attention and sets the tone for the rest of the blog post. The introduction should provide a brief overview of the topic and what the reader can expect to learn.\n",
            "\n",
            "---\n",
            "\n",
            "Section 1: The Importance of Journalistic Best Practices\n",
            "\n",
            "As a content editor, following journalistic best practices is crucial to ensure that the blog post is unbiased, accurate, and provides value to the reader. Adhering to these practices not only helps to establish credibility but also ensures that the information presented is trustworthy.\n",
            "\n",
            "---\n",
            "\n",
            "Section 2: Balanced Viewpoints\n",
            "\n",
            "Providing balanced viewpoints when offering opinions or assertions is essential to creating a well-rounded and informative blog post. This involves presenting both sides of an argument and allowing the reader to make their own informed decision.\n",
            "\n",
            "---\n",
            "\n",
            "Section 3: Avoiding Controversial Topics\n",
            "\n",
            "While it is essential to address relevant and timely topics, avoiding major controversial topics or opinions is often necessary to maintain a professional and unbiased tone. This helps to ensure that the blog post is accessible to a wider audience and is not likely to offend or alienate readers.\n",
            "\n",
            "---\n",
            "\n",
            "Section 4: Aligning with the Organization's Style\n",
            "\n",
            "As a content editor, it is crucial to ensure that the blog post aligns with the organization's style and tone. This involves using consistent formatting, language, and branding throughout the post.\n",
            "\n",
            "---\n",
            "\n",
            "Conclusion:\n",
            "\n",
            "A well-written and informative conclusion is the final touch to a great blog post. The conclusion should summarize the key takeaways and leave the reader with a clear understanding of the topic.\n",
            "\n",
            "---\n",
            "\n",
            "Note: The above content is just a template and should be customized based on the specific blog post and the organization's style guide.\u001b[00m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92m1. Use the content plan to craft a compelling blog post on Pakistan Vs India .\n",
            "2. Incorporate SEO keywords naturally.\n",
            "3. Sections/Subtitles are properly named in an engaging manner.\n",
            "4. Ensure the post is structured with an engaging introduction, insightful body, and a summarizing conclusion.\n",
            "5. Proofread for grammatical errors and alignment with the brand's voice.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Introduction:\n",
            "\n",
            "The long-standing rivalry between Pakistan and India is a topic that has been discussed and analyzed for decades. From politics to sports, the two countries have a history of competition and conflict. In this blog post, we will explore the complex relationship between Pakistan and India, focusing on journalistic best practices, balanced viewpoints, and avoiding controversial topics.\n",
            "\n",
            "---\n",
            "\n",
            "Section 1: The Importance of Journalistic Best Practices\n",
            "\n",
            "When writing about the topic \"Pakistan vs India,\" it is crucial to follow journalistic best practices to ensure that the information presented is unbiased, accurate, and provides value to the reader. Adhering to these practices not only helps to establish credibility but also ensures that the information presented is trustworthy.\n",
            "\n",
            "For example, using reliable sources to gather information, double-checking facts, and providing context to help the reader understand the topic better are all essential journalistic best practices. Additionally, avoiding sensationalism, bias, and speculation is crucial to maintaining a professional and unbiased tone.\n",
            "\n",
            "---\n",
            "\n",
            "Section 2: Balanced Viewpoints\n",
            "\n",
            "Providing balanced viewpoints when offering opinions or assertions is essential to creating a well-rounded and informative blog post. This involves presenting both sides of an argument and allowing the reader to make their own informed decision.\n",
            "\n",
            "For instance, when discussing the political tensions between Pakistan and India, it is essential to provide context and background information about the disputes, as well as the positions of both countries. This can help the reader to understand the complexities of the issue and form their own opinion.\n",
            "\n",
            "---\n",
            "\n",
            "Section 3: Avoiding Controversial Topics\n",
            "\n",
            "While it is essential to address relevant and timely topics, avoiding major controversial topics or opinions is often necessary to maintain a professional and unbiased tone. This helps to ensure that the blog post is accessible to a wider audience and is not likely to offend or alienate readers.\n",
            "\n",
            "For example, when discussing the cricket rivalry between Pakistan and India, it is best to focus on the sport itself and the skills of the players, rather than making controversial statements about nationalism or patriotism.\n",
            "\n",
            "---\n",
            "\n",
            "Section 4: Aligning with the Organization's Style\n",
            "\n",
            "As a content editor, it is crucial to ensure that the blog post aligns with the organization's style and tone. This involves using consistent formatting, language, and branding throughout the post.\n",
            "\n",
            "For instance, if the organization's style guide emphasizes a conversational tone, it is essential to use language and formatting that reflects this style. This can help to create a consistent and professional image for the organization.\n",
            "\n",
            "---\n",
            "\n",
            "Conclusion:\n",
            "\n",
            "In conclusion, when writing about the topic \"Pakistan vs India,\" it is essential to follow journalistic best practices, provide balanced viewpoints, avoid controversial topics, and align with the organization's style. By doing so, you can create a well-written and informative blog post that provides value to the reader and establishes credibility for your organization.\n",
            "\n",
            "Remember to always double-check your facts, provide context, and avoid sensationalism or bias. By doing so, you can create a blog post that is both informative and unbiased, providing value to your readers and establishing your organization as a trusted source of information.\u001b[00m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Editor\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mProofread the given blog post for grammatical errors and alignment with the brand's voice.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Editor\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Introduction:\n",
            "\n",
            "The long-standing rivalry between Pakistan and India is a topic that has been discussed and analyzed for decades. From politics to sports, the two countries have a history of competition and conflict. In this blog post, we will explore the complex relationship between Pakistan and India, focusing on journalistic best practices, balanced viewpoints, and avoiding controversial topics.\n",
            "\n",
            "Section 1: The Importance of Journalistic Best Practices\n",
            "\n",
            "When writing about the topic \"Pakistan vs India,\" it is crucial to follow journalistic best practices to ensure that the information presented is unbiased, accurate, and provides value to the reader. Adhering to these practices not only helps to establish credibility but also ensures that the information presented is trustworthy.\n",
            "\n",
            "For example, using reliable sources to gather information, double-checking facts, and providing context to help the reader understand the topic better are all essential journalistic best practices. Additionally, avoiding sensationalism, bias, and speculation is crucial to maintaining a professional and unbiased tone. At [Organization], we prioritize fact-checking and ensuring that our sources are trustworthy. Our goal is to provide our readers with accurate and reliable information that they can use to make informed decisions.\n",
            "\n",
            "Section 2: Balanced Viewpoints\n",
            "\n",
            "Providing balanced viewpoints when offering opinions or assertions is essential to creating a well-rounded and informative blog post. This involves presenting both sides of an argument and allowing the reader to make their own informed decision.\n",
            "\n",
            "For instance, when discussing the political tensions between Pakistan and India, it is essential to provide context and background information about the disputes, as well as the positions of both countries. At [Organization], we believe in presenting a balanced viewpoint, even when discussing complex and sensitive topics. Our goal is to help our readers understand the nuances of an issue and make informed decisions.\n",
            "\n",
            "Section 3: Avoiding Controversial Topics\n",
            "\n",
            "While it is essential to address relevant and timely topics, avoiding major controversial topics or opinions is often necessary to maintain a professional and unbiased tone. This helps to ensure that the blog post is accessible to a wider audience and is not likely to offend or alienate readers.\n",
            "\n",
            "For example, when discussing the cricket rivalry between Pakistan and India, it is best to focus on the sport itself and the skills of the players, rather than making controversial statements about nationalism or patriotism. At [Organization], we prioritize inclusivity and respect for all viewpoints. Our goal is to create content that is accessible and engaging for a diverse audience.\n",
            "\n",
            "Section 4: Aligning with the Organization's Style\n",
            "\n",
            "As a content editor, it is crucial to ensure that the blog post aligns with the organization's style and tone. This involves using consistent formatting, language, and branding throughout the post.\n",
            "\n",
            "For instance, if the organization's style guide emphasizes a conversational tone, it is essential to use language and formatting that reflects this style. At [Organization], we prioritize a friendly and approachable tone that resonates with our audience. Our goal is to create content that is easy to read and engaging for our community.\n",
            "\n",
            "Conclusion:\n",
            "\n",
            "In conclusion, when writing about the topic \"Pakistan vs India,\" it is essential to follow journalistic best practices, provide balanced viewpoints, avoid controversial topics, and align with the organization's style. By doing so, you can create a well-written and informative blog post that provides value to the reader and establishes credibility for your organization.\n",
            "\n",
            "Remember to always double-check your facts, provide context, and avoid sensationalism or bias. By doing so, you can create a blog post that is both informative and unbiased, providing value to your readers and establishing your organization as a trusted source of information. At [Organization], we are committed to upholding these standards in all of our content.\u001b[00m\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(result.raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "4GBz3edvN1wu",
        "outputId": "2a684bf9-649b-4e97-ffd0-6e0438be19c4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Introduction:\n\nThe long-standing rivalry between Pakistan and India is a topic that has been discussed and analyzed for decades. From politics to sports, the two countries have a history of competition and conflict. In this blog post, we will explore the complex relationship between Pakistan and India, focusing on journalistic best practices, balanced viewpoints, and avoiding controversial topics.\n\nSection 1: The Importance of Journalistic Best Practices\n\nWhen writing about the topic \"Pakistan vs India,\" it is crucial to follow journalistic best practices to ensure that the information presented is unbiased, accurate, and provides value to the reader. Adhering to these practices not only helps to establish credibility but also ensures that the information presented is trustworthy.\n\nFor example, using reliable sources to gather information, double-checking facts, and providing context to help the reader understand the topic better are all essential journalistic best practices. Additionally, avoiding sensationalism, bias, and speculation is crucial to maintaining a professional and unbiased tone. At [Organization], we prioritize fact-checking and ensuring that our sources are trustworthy. Our goal is to provide our readers with accurate and reliable information that they can use to make informed decisions.\n\nSection 2: Balanced Viewpoints\n\nProviding balanced viewpoints when offering opinions or assertions is essential to creating a well-rounded and informative blog post. This involves presenting both sides of an argument and allowing the reader to make their own informed decision.\n\nFor instance, when discussing the political tensions between Pakistan and India, it is essential to provide context and background information about the disputes, as well as the positions of both countries. At [Organization], we believe in presenting a balanced viewpoint, even when discussing complex and sensitive topics. Our goal is to help our readers understand the nuances of an issue and make informed decisions.\n\nSection 3: Avoiding Controversial Topics\n\nWhile it is essential to address relevant and timely topics, avoiding major controversial topics or opinions is often necessary to maintain a professional and unbiased tone. This helps to ensure that the blog post is accessible to a wider audience and is not likely to offend or alienate readers.\n\nFor example, when discussing the cricket rivalry between Pakistan and India, it is best to focus on the sport itself and the skills of the players, rather than making controversial statements about nationalism or patriotism. At [Organization], we prioritize inclusivity and respect for all viewpoints. Our goal is to create content that is accessible and engaging for a diverse audience.\n\nSection 4: Aligning with the Organization's Style\n\nAs a content editor, it is crucial to ensure that the blog post aligns with the organization's style and tone. This involves using consistent formatting, language, and branding throughout the post.\n\nFor instance, if the organization's style guide emphasizes a conversational tone, it is essential to use language and formatting that reflects this style. At [Organization], we prioritize a friendly and approachable tone that resonates with our audience. Our goal is to create content that is easy to read and engaging for our community.\n\nConclusion:\n\nIn conclusion, when writing about the topic \"Pakistan vs India,\" it is essential to follow journalistic best practices, provide balanced viewpoints, avoid controversial topics, and align with the organization's style. By doing so, you can create a well-written and informative blog post that provides value to the reader and establishes credibility for your organization.\n\nRemember to always double-check your facts, provide context, and avoid sensationalism or bias. By doing so, you can create a blog post that is both informative and unbiased, providing value to your readers and establishing your organization as a trusted source of information. At [Organization], we are committed to upholding these standards in all of our content."
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Pq1qd9ZYPnLl"
      }
    }
  ]
}